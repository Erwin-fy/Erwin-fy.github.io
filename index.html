<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Kategorien
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-categories " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/09/DeepLab/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Erwin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/09/DeepLab/" itemprop="url">Semantic Segmentation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-09T11:10:22+08:00">
                2017-12-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h2><p><strong>Abstract</strong>: <strong>Deep Convolutional Nets &#160; Atrous Convolution &#160; Fully Connected CRFs</strong></p>
<p><a href="https://arxiv.org/pdf/1606.00915.pdf" target="_blank" rel="external">Link</a></p>
<h3 id="1-Overall-Archetecture"><a href="#1-Overall-Archetecture" class="headerlink" title="1. Overall Archetecture"></a>1. Overall Archetecture</h3><p><img src="/2017/12/09/DeepLab/DeepLab.png" alt="DeepLab"></p>
<h3 id="2-Models"><a href="#2-Models" class="headerlink" title="2. Models"></a>2. Models</h3><h4 id="2-1-DCNN-amp-amp-Atrous-Convolution"><a href="#2-1-DCNN-amp-amp-Atrous-Convolution" class="headerlink" title="2.1 DCNN &amp;&amp; Atrous Convolution"></a>2.1 DCNN &amp;&amp; Atrous Convolution</h4><ul>
<li><p><strong><em>DCNN</em></strong></p>
<p> We adopt <strong><em>VGG16</em></strong> and <strong><em>ResNet101</em></strong> to extract feature. And we repalce their fully-connected layers with fully-convolutional layers.</p>
</li>
<li><p><strong><em>Atrous Convolution</em></strong></p>
<p>Atrous Convolution allows us to compute feature maps more densely and enlarge the $field-of-view$ of filters.</p>

</li>
</ul>
<p>First, consider one-dimensional signals.<br><img src="/2017/12/09/DeepLab/origin.png" alt="Original Structure"><br><img src="/2017/12/09/DeepLab/sparse.png" alt="Sparse Structure"><br><img src="/2017/12/09/DeepLab/dense.png" alt="Dense Structure"></p>
<p>Obviously. we can see <strong><em>Atrous Convolution</em></strong> helps to resize a 3-dimensional filter to a 5-dimensional one, in fact. Compared with <strong><em>Original Structure</em></strong>, we attain mere resolution enhancement due to 1 stride in <strong>MAX Pooling Layer</strong>. Compared with <strong><em>Sparse Structure</em></strong>, the field-of-view of filters can be enlarged to the same as <strong><em>Original Structure</em></strong>.</p>
<p>By the way, when dilation=1(rate is refered to as dilation in papaer), <strong><em>Dense Structure</em></strong> and <strong><em>Sparse Structure</em></strong> are the same.</p>
<p>In conclusion, given a $k<em>k$ filter, Atrous Convolution can enlarge the kernel size from $k$ to $k_e=k + (k-1)</em>(dilation-1)$ without increasing the number of parameters.</p>
<h4 id="2-2-Atrous-Spatial-Pyramid-Pooling-2-approaches"><a href="#2-2-Atrous-Spatial-Pyramid-Pooling-2-approaches" class="headerlink" title="2.2 Atrous Spatial Pyramid Pooling(2 approaches)"></a>2.2 Atrous Spatial Pyramid Pooling(2 approaches)</h4><h5 id="2-2-1-Standard-MultiScale-Processing"><a href="#2-2-1-Standard-MultiScale-Processing" class="headerlink" title="2.2.1 Standard MultiScale Processing"></a>2.2.1 Standard MultiScale Processing</h5><ul>
<li>Three rescaled versions of the original image.</li>
<li>Three parallel DCNN branches share the same parameters.</li>
<li>Bilinearly interplote the feature maps to the original image resolution.</li>
<li>Fuse 3 branches by taking maximum.</li>
</ul>
<h5 id="2-2-2-Different-sampling-rates"><a href="#2-2-2-Different-sampling-rates" class="headerlink" title="2.2.2 Different sampling rates"></a>2.2.2 Different sampling rates</h5><ul>
<li>Employ multiple parallel atrous convolutional filters with different rates(dilations).</li>
<li>Fuse them by taking SUM</li>
</ul>
<h4 id="Let’s-take-VGG16-as-an-example"><a href="#Let’s-take-VGG16-as-an-example" class="headerlink" title="Let’s take VGG16 as an example:"></a>Let’s take VGG16 as an example:</h4><h4 id="2-3-CRF"><a href="#2-3-CRF" class="headerlink" title="2.3 CRF"></a>2.3 CRF</h4>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-categories " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/05/WSL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Erwin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/05/WSL/" itemprop="url">Weakly Supervised Learning for Classification, Localization and Segmentation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-05T22:15:38+08:00">
                2017-10-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-What-is-Weakly-Supervised-Learning"><a href="#1-What-is-Weakly-Supervised-Learning" class="headerlink" title="1. What is Weakly Supervised Learning"></a>1. What is <em>Weakly Supervised Learning</em></h2><h3 id="1-1-Localization"><a href="#1-1-Localization" class="headerlink" title="1.1 Localization"></a>1.1 Localization</h3><p>Labels in <em><strong>Weakly</strong></em> Supervised Learning: <strong>image-level class</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Label</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/2017/10/05/WSL/image.jpg" alt="Image"></td>
<td style="text-align:center"><strong>Vehicle</strong></td>
</tr>
</tbody>
</table>
<p>Labels in <strong>fully</strong> Supervised Learning: <strong>bbox-level</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Label</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/2017/10/05/WSL/image.jpg" alt="Image"></td>
<td style="text-align:center"><img src="/2017/10/05/WSL/bbox.png" alt="Label"></td>
</tr>
</tbody>
</table>
<h3 id="1-2-Segmentation"><a href="#1-2-Segmentation" class="headerlink" title="1.2 Segmentation"></a>1.2 Segmentation</h3><p>Labels in <em><strong>Weakly</strong></em> Supervised Learning: image-level class,  bbox-level</p>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Label</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/2017/10/05/WSL/image.jpg" alt="Image"></td>
<td style="text-align:center"><strong>Vehicle</strong>  or <img src="/2017/10/05/WSL/bbox.png" alt="Label"></td>
</tr>
</tbody>
</table>
<p>Labels in <strong>fully</strong> Supervised Learning: <strong>pixel-level</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Label</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/2017/10/05/WSL/image.jpg" alt="Image"></td>
<td style="text-align:center"><img src="/2017/10/05/WSL/seg.png" alt="Label"></td>
</tr>
</tbody>
</table>
<h2 id="2-Why-Weakly-Supervised-Learning"><a href="#2-Why-Weakly-Supervised-Learning" class="headerlink" title="2. Why Weakly Supervised Learning"></a>2. Why <em>Weakly Supervised Learning</em></h2><p>Obviously, easier to get data, however, lower accuracy.</p>
<hr>
<h1 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a>Paper</h1><h2 id="I-Learning-Deep-Features-for-Discriminative-Localization"><a href="#I-Learning-Deep-Features-for-Discriminative-Localization" class="headerlink" title="I. Learning Deep Features for Discriminative Localization"></a>I. Learning Deep Features for Discriminative Localization</h2><p>Abstract: <strong>GAP</strong>(Global Average Pooling)  &#160;  <strong>CAM</strong>(Class Activation Mapping)</p>
<p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf" target="_blank" rel="external">Link</a></p>
<h3 id="1-Overall-Archetecture"><a href="#1-Overall-Archetecture" class="headerlink" title="1. Overall Archetecture"></a>1. Overall Archetecture</h3><p><img src="/2017/10/05/WSL/Discriminative.png" alt="Discriminative"></p>
<h3 id="2-Class-Activation-Mapping"><a href="#2-Class-Activation-Mapping" class="headerlink" title="2. Class Activation Mapping"></a>2. Class Activation Mapping</h3><p>In the last convolutional layer($H<em>W</em>1024$), and given a unit k, we can get a  scalar $F$<sup>$k$</sup> $(F<em>k = Avg(\sum</em>{x,y}{f_k(x, y)})$ after performing <strong>Global Average Pooling</strong>. </p>
<p>So given 1024 units, we can get a 1024-dim vector $F$. In the next fully-connected layer(the input to the softmax), we can get score for class c: $S_c = w^cF$ .</p>
<p>And with the predicts and labels, we can compute loss using SoftmaxWithLoss, and minimize the loss we can get <strong>optimal parmeter $w$</strong>. </p>
<p>The process is as follows:<br><img src="/2017/10/05/WSL/CAM.png" alt="CAM"></p>
<p>For the class c, we compute <em>CAM</em> via $M<em>c = \sum</em>{k}{w_k^cf_k(x,y)}$</p>
<h3 id="3-Localization-threshold-阈值-largest-connected-component（最大连通区域）and-upsample"><a href="#3-Localization-threshold-阈值-largest-connected-component（最大连通区域）and-upsample" class="headerlink" title="3. Localization(threshold(阈值), largest connected component（最大连通区域）and upsample)"></a>3. Localization(threshold(阈值), largest connected component（最大连通区域）and upsample)</h3><p>According to the Classification, we select top-5(or top-1) predicted categories and we get 5(or 1) Class Activation Maps.</p>
<p>We use a simple thresholding technique to segment the heatmap. We first segment the regions of which the value is above 20% of the max value of the CAM. Then we take the bounding box that covers the largest connected component in the segmentation map. Finally we should resize the map to the same size of input.</p>
<hr>
<p>title: WSL<br>date: 2017-09-17 22:26:27</p>
<h2 id="tags"><a href="#tags" class="headerlink" title="tags:"></a>tags:</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/17/Instance-Segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Erwin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/17/Instance-Segmentation/" itemprop="url">Instance Segmentation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-17T10:44:45+08:00">
                2017-07-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/cate/" itemprop="url" rel="index">
                    <span itemprop="name">cate</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Instance-aware-Semantic-Segmentation-via-Multi-task-Network-Cascades"><a href="#Instance-aware-Semantic-Segmentation-via-Multi-task-Network-Cascades" class="headerlink" title="Instance-aware Semantic Segmentation via Multi-task Network Cascades"></a>Instance-aware Semantic Segmentation via Multi-task Network Cascades</h1><h2 id="1-Overall-Architeture-3-stages"><a href="#1-Overall-Architeture-3-stages" class="headerlink" title="1. Overall Architeture(3 stages)"></a>1. Overall Architeture(3 stages)</h2><p><img src="/2017/07/17/Instance-Segmentation/MNC.png" alt="MNC"></p>
<h2 id="2-1-Stage1-Regressing-Box-level-Instances-class-agnostic"><a href="#2-1-Stage1-Regressing-Box-level-Instances-class-agnostic" class="headerlink" title="2.1    Stage1: Regressing Box-level Instances(class-agnostic)"></a>2.1    Stage1: Regressing Box-level Instances(class-agnostic)</h2><p>    <strong>RPN network</strong>(the same as the faster rcnn’s) predicts bounding box locations(<strong>4*9</strong>) and objectness scores(<strong>2*9</strong>).<br>    For the bbox $i$, let $B$<sub>i</sub> = {$x$<sub>i</sub>, $y$<sub>i</sub>, $w$<sub>i</sub>, $h$<sub>$i$</sub>, $p$<sub>i</sub>},<br>    <strong>$L$<sub>1 i</sub> = SmoothL1Loss($x$<sub>i</sub>, $y$<sub>i</sub>, $w$<sub>i</sub>, $h$<sub>i</sub>) + SoftmaxLoss($p$<sub>i</sub>)</strong> </p>

<h2 id="2-2-Stage2-Regressing-Mask-level-Instances-class-agnostic"><a href="#2-2-Stage2-Regressing-Mask-level-Instances-class-agnostic" class="headerlink" title="2.2 Stage2: Regressing Mask-level Instances(class-agnostic)"></a>2.2 Stage2: Regressing Mask-level Instances(class-agnostic)</h2><p> Generate 300 proposals from  Stage1’s bboxes via <strong>NMS</strong>. Given the bboexs and feature map(Conv5_3), RoI warping layer interpolates(bilinear) the features inside the bbox and outputs the features(28*28), (We can get the weights relative to the pixel of Conv5_3 at (u,v), then use bilinear interpolates).<br>    A max pooling layer is then applied to produce a lower-resolution output(14*14).<br>    Following 2 fc layers generate m<sup>2</sup> outputs, each performing binary logistic regression to the ground truth mask(m=28, but it is 21 in caffe code??).<br>    <strong>$L$<sub>2</sub> = SigmoidEntropyLoss(mask_pred, gt)</strong> </p>


<h2 id="2-3-Stage3-Categorizing-Instances"><a href="#2-3-Stage3-Categorizing-Instances" class="headerlink" title="2.3 Stage3: Categorizing Instances"></a>2.3 Stage3: Categorizing Instances</h2><p> Mask-base: Generate mask_proposal by combining mask_pred and proposal and resize it to RoI pooled resolution(14*14). The masked feature is given by element-wise product:<br>        $feature_roi_mask = mask_proposal * RoI Pooled$, followed by the 2 fc layers.<br>    Box-base: Append 2 fc layers to the RoI pooled feature.<br>    Concat 2 pathways, and outputs cls_scores(21), seg_cls_scores(21) and bbox_pred(84).<br>    <strong>$L$<sub>3</sub> = SoftmaxLoss(cls_scores) + SoftmaxLoss(seg_cls_scores) + SmoothL1Loss(bbox_pred)</strong> </p>



<h2 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h2><p> mAP<sup>r</sup>@0.5:63.5%<br>    mAP<sup>r</sup>@0.7:41.5%<br>    time/img: 0.36s<br></p>

<p> According to the speed, it is slow. I think the main reason is the faster rcnn model is not fast enough, and there are some fc layers.<br>    According to the mAP, due to cascades, if Stage 1 and 2 are not effective, the result will be not ideal.<br></p>

<hr>
<h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><h2 id="1-Core-Architecture"><a href="#1-Core-Architecture" class="headerlink" title="1. Core Architecture"></a>1. Core Architecture</h2><p>Faster R-CNN + RoIAlign + Mask-Branch</p>
<h2 id="2-RoIPool-RoIWarp-RoIAlign"><a href="#2-RoIPool-RoIWarp-RoIAlign" class="headerlink" title="2. RoIPool RoIWarp RoIAlign"></a>2. RoIPool RoIWarp RoIAlign</h2><p>    Faster R-CNN produces a conv feature map with several convolutional (conv) and max pooling layers(e.g., VGG16). After RPN network, original RoI regions are maped to this       conv layer, called proposals(r,c,w,h).<br><br>    RoIPool takes proposals as inputs and divides the h × w proposals(RoI) into an H × W grid of sub-windows of approximate size h/H × w/W. And then max-pooling or         avg-pooling is applied to each sub-window. So the outputs are the feature maps with fixed size (H × W).<br><br>    Similar to RoIPool, RoIWarp has been discussed in MNC, adopting bilinear interpolation.<br><br>    Taking alignment into consideration, RoIAlign avoid any quantization. For example, if we want to tansform a 7*7 RoI into 3*3 feature map. How to process by using RoIPool? Let the size of sub-window is <strong><em>cell(7/3)</em></strong> and the sliding stride is <strong><em>floor(7/3)</em></strong>, so these quantization cause misalignments.<br>    But with RoIAlign, we use <strong><em>(7/3)</em></strong> and compute via bilinear interpolation. </p>

<h2 id="3-Loss-Multi-Task"><a href="#3-Loss-Multi-Task" class="headerlink" title="3. Loss(Multi-Task)"></a>3. Loss(Multi-Task)</h2><p>    <strong><em>L</em> = <em>L<sub>cls</sub></em> + <em>L<sub>box</sub></em> + <em>L<sub>mask</sub></em></strong><br><br>    <strong><em>L<sub>cls</sub></em></strong> and <strong><em>L<sub>box</sub></em></strong> are the same as Faster R-CNN’s.<br>    The mask branch has a <strong>K*m*m</strong> dimensional output and <strong><em>L<sub>mask</sub></em></strong> is only defined on the k-th mask(SigmoidEntropyLoss). </p>


<hr>
<h1 id="Semantic-Instance-Segmentation-via-Deep-Metric-Learning"><a href="#Semantic-Instance-Segmentation-via-Deep-Metric-Learning" class="headerlink" title="Semantic Instance Segmentation via Deep Metric Learning"></a>Semantic Instance Segmentation via Deep Metric Learning</h1><p>This approach is different from the above two papers which are based on the <strong>RCNN</strong>, and it combines deep fully conv network and metric learning</p>

<h2 id="1-Deep-Metric-Learning"><a href="#1-Deep-Metric-Learning" class="headerlink" title="1. Deep Metric Learning"></a>1. Deep Metric Learning</h2><h3 id="1-1-Metric-Learning"><a href="#1-1-Metric-Learning" class="headerlink" title="1.1 Metric Learning"></a>1.1 Metric Learning</h3><p>    Construct a distance function and compute similarity.<br>    <a href="http://blog.csdn.net/nehemiah_li/article/details/44230053" target="_blank" rel="external">Refer to this blog</a> </p>

<h3 id="1-2-Deep-Metric-Learning"><a href="#1-2-Deep-Metric-Learning" class="headerlink" title="1.2 Deep Metric Learning"></a>1.2 Deep Metric Learning</h3><p>    In this paper, based on the deep fully conv embedding model, compute how likely two pixels are to belong to the same object and group similar pixels.  </p>

<h2 id="2-Overall-Architecture"><a href="#2-Overall-Architecture" class="headerlink" title="2. Overall Architecture"></a>2. Overall Architecture</h2><p><img src="/2017/07/17/Instance-Segmentation/DMetricL.png" alt="DMetricL"></p>
<h2 id="3-Model"><a href="#3-Model" class="headerlink" title="3. Model"></a>3. Model</h2><h3 id="3-1-Embedding-vectors"><a href="#3-1-Embedding-vectors" class="headerlink" title="3.1 Embedding vectors"></a>3.1 Embedding vectors</h3><p>    Take as input a feature map and output a $[h,w,d]$ tensor. Thus each pixel $p$ in image is represented by $d$-dimensional embedding vector $e$<sub>p</sub>.<br>    Define the similarity between pixels $p$ and $q$ as Equation(1) and then define the loss function <strong><em>L<sub>e</sub></em></strong>(similar to logistic regression)  </p>

<h3 id="3-2-Creating-masks"><a href="#3-2-Creating-masks" class="headerlink" title="3.2 Creating masks"></a>3.2 Creating masks</h3><p>    Each pixel $p$ will generate a mask if picked as a seed, by finding all the other pixels $q$ that have a similarity with $p$ greater than a threshold $\tau$:<br>    <strong>$mask(p, \tau)$ = { $q$: $\sigma$ $(p, q)$ $\geq$ $\tau$ }</strong><br></p>


<h3 id="3-3-Classification"><a href="#3-3-Classification" class="headerlink" title="3.3 Classification"></a>3.3 Classification</h3><p>     The model also takes as input a feature map and outputs a $[h,w,C+1]$ tensor, predicting the class of each mask generated by each pixel. We can get <strong><em>L<sub>cls</sub></em></strong>     using softmax cross-entropy loss. And the ground truth label is assigned to the pixel $p$ via IoU threshold between the proposed mask and ground truth masks. </p>

<h3 id="3-4-Seediness"><a href="#3-4-Seediness" class="headerlink" title="3.4 Seediness"></a>3.4 Seediness</h3><p>    It is obvious that the seediness tensor is computed from the classification tensor.<br>    Define the “seediness” of pixel p to be<br>    $S$<sub>p</sub> = $max$ $max$ $C$<sub>pc</sub><sup>$\tau$</sup><br>    ($C$<sub>pc</sub><sup>$\tau$</sup> represent the probability that pixel $p$ is a good seed for an instance class $c$ when using similarity threshold $\tau$.) </p>

<h3 id="3-5-Choose-the-seeds"><a href="#3-5-Choose-the-seeds" class="headerlink" title="3.5 Choose the seeds"></a>3.5 Choose the seeds</h3><p>    According to ‘Seediness’ heatmap $S$<sub>p</sub> and Section 3.3 in the paper, we can choose good seeds. Then we will attain the mask and confidence score around the seeds with section 3.2, 3.3 and 3.4 </p>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Erwin" />
          <p class="site-author-name" itemprop="name">Erwin</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">Artikel</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">Kategorien</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Erwin</span>
</div>


<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
